{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a929beac-32dd-4a62-9e85-41b371f9b814",
   "metadata": {},
   "source": [
    "### 1 - Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6335076a-48da-40bd-9d24-8115b1f86657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "## Encoding, Decoding, Text Transformation\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Grid Search CV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "## Models\n",
    "from sklearn.neighbors import KNeighborsClassifier                     # KNN\n",
    "from sklearn.linear_model import LogisticRegression                    # Logistic Regression\n",
    "from sklearn.svm import SVC                                            # Support Vector Machine\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB # Navie Bayes\n",
    "\n",
    "## Evaluation\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2478df9-a791-4f2b-a26c-7c1500c76872",
   "metadata": {},
   "source": [
    "### 2 - Understanding the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aafd7b-b220-4017-b4d8-50aa709e4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reading data from text files as CSV\n",
    "df_1 = pd.read_csv('sorted females.txt', names=['Name'])\n",
    "df_2 = pd.read_csv('sorted males.txt', names=['Name'])\n",
    "\n",
    "## Creating gender column \n",
    "df_1['Gender'] = '0'                    # 0 for female\n",
    "df_2['Gender'] = '1'                    # 1 for male\n",
    "\n",
    "## Combining two dataframe\n",
    "df = pd.concat([df_1,df_2], axis=0)\n",
    "\n",
    "print(df.sample(5))\n",
    "print('\\nRows & Columns : ', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8786b208-c173-43e0-8abe-a851b1591b39",
   "metadata": {},
   "source": [
    "### 3 - Data-cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c957fbe-42f0-4e07-b3c5-9d05ff858cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checing and Handling Null\n",
    "print('Null :\\n' ,df.isnull().sum())\n",
    "df = df.dropna()\n",
    "\n",
    "## Checking and Handling Duplicates\n",
    "df.drop_duplicates(inplace = True)\n",
    "print('\\nRows and Columns : ',df.shape)\n",
    "\n",
    "## Lower-case Convertion\n",
    "df.iloc[::,:-1] = df.iloc[::,:-1].apply(lambda x: x.str.lower())\n",
    "df.sample(3)\n",
    "\n",
    "## feature Selection\n",
    "y = df.Gender.values\n",
    "X = df.Name.values\n",
    "\n",
    "## Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83f7244-c0a8-49c7-8dc4-7b310372fa60",
   "metadata": {},
   "source": [
    "### 4 - Model Development and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a16160-f413-483b-9049-0abc6520cbff",
   "metadata": {},
   "source": [
    "##### 4 . 1 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3e57ca-409d-42fa-9e63-b17c208198b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "steps = [('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "         ('knn', KNeighborsClassifier(n_neighbors = 3))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "## Grid Search CV\n",
    "parameters = {'knn__n_neighbors': [3,5,7,9,11,13,15,17,19]}\n",
    "knn_pipeline = GridSearchCV(pipeline, parameters, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "## Fitting\n",
    "knn_pipeline.fit(X_train, y_train)\n",
    "\n",
    "## Best parameter\n",
    "print(\"Best parameters:\", knn_pipeline.best_params_)\n",
    "\n",
    "## Evaluation\n",
    "## Training\n",
    "print('KNN')\n",
    "print('---Training Results---')\n",
    "ypred_train = knn_pipeline.predict(X_train)\n",
    "mat_clf_train = confusion_matrix(y_train, ypred_train)\n",
    "report_clf_train = classification_report(y_train, ypred_train)\n",
    "print(mat_clf_train)\n",
    "print(report_clf_train)\n",
    "# ROC\n",
    "ypred_trainP = knn_pipeline.predict_proba(X_train)\n",
    "auc_train_knn = roc_auc_score(y_train, ypred_trainP[:,1])\n",
    "print(auc_train_knn)\n",
    "\n",
    "## Testing\n",
    "print('\\n---Testing Results---')\n",
    "ypred_test = knn_pipeline.predict(X_test)\n",
    "mat_clf_test = confusion_matrix(y_test, ypred_test)\n",
    "report_clf_test = classification_report(y_test, ypred_test)\n",
    "print(mat_clf_test)\n",
    "print(report_clf_test)\n",
    "# ROC\n",
    "ypred_testP = knn_pipeline.predict_proba(X_test)\n",
    "auc_test_knn = roc_auc_score(y_test, ypred_testP[:,1])\n",
    "print(auc_test_knn)\n",
    "\n",
    "## storing f1, precison, recall scores for comparison\n",
    "# f1\n",
    "f1_test_0_knn = f1_score(y_test, ypred_test, pos_label='0') # 0 = Female\n",
    "f1_test_1_knn = f1_score(y_test, ypred_test, pos_label='1') # 1 = Male\n",
    "# precision\n",
    "precision_test_0_knn = precision_score(y_test, ypred_test, pos_label='0')\n",
    "precision_test_1_knn = precision_score(y_test, ypred_test, pos_label='1')\n",
    "# recall\n",
    "recall_test_0_knn = recall_score(y_test, ypred_test, pos_label='0')\n",
    "recall_test_1_knn = recall_score(y_test, ypred_test, pos_label='1')\n",
    "# accuracy\n",
    "accuracy_test_knn = accuracy_score(y_test, ypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21d80f8-aff7-4c85-8f25-418dc2a76beb",
   "metadata": {},
   "source": [
    "##### 4 . 2 - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62651c53-af3b-4df5-9b8c-3e5529a33156",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "steps = [('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "         ('tfidf', TfidfTransformer()),\n",
    "         ('logReg', LogisticRegression(penalty = \"l2\", C = 10))]\n",
    "\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "## Grid Search CV\n",
    "para = {'logReg__C': [0.001, 0.01, 0.1, 1.0, 10.0, 100.00]}\n",
    "lr_pipeline = GridSearchCV(pipeline, para, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "## Fitting\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "## Best Parameter\n",
    "print(\"\\nBest parameters:\", lr_pipeline.best_params_)\n",
    "\n",
    "## Evaluation\n",
    "##Training\n",
    "print('Logistic Regression')\n",
    "print('---Training Results---')\n",
    "ypred_train = lr_pipeline.predict(X_train)\n",
    "mat_clf_train = confusion_matrix(y_train, ypred_train)\n",
    "report_clf_train = classification_report(y_train, ypred_train)\n",
    "print(mat_clf_train)\n",
    "print(report_clf_train)\n",
    "# ROC\n",
    "ypred_trainP = lr_pipeline.predict_proba(X_train)\n",
    "auc_train_lr = roc_auc_score(y_train, ypred_trainP[:,1])\n",
    "print(auc_train_lr)\n",
    "\n",
    "## Testing\n",
    "print('\\n---Testing Results---')\n",
    "ypred_test = lr_pipeline.predict(X_test)\n",
    "mat_clf_test = confusion_matrix(y_test, ypred_test)\n",
    "report_clf_test = classification_report(y_test, ypred_test)\n",
    "print(mat_clf_test)\n",
    "print(report_clf_test)\n",
    "# ROC\n",
    "ypred_testP = lr_pipeline.predict_proba(X_test)\n",
    "auc_test_lr = roc_auc_score(y_test, ypred_testP[:,1])\n",
    "print(auc_test_lr)\n",
    "\n",
    "## Storing f1, precison, recall scores for comparison\n",
    "# f1\n",
    "f1_test_0_lr = f1_score(y_test, ypred_test, pos_label='0')\n",
    "f1_test_1_lr = f1_score(y_test, ypred_test, pos_label='1')\n",
    "# precision\n",
    "precision_test_0_lr = precision_score(y_test, ypred_test, pos_label='0')\n",
    "precision_test_1_lr = precision_score(y_test, ypred_test, pos_label='1')\n",
    "# recall\n",
    "recall_test_0_lr = recall_score(y_test, ypred_test, pos_label='0')\n",
    "recall_test_1_lr = recall_score(y_test, ypred_test, pos_label='1')\n",
    "# accuracy\n",
    "accuracy_test_lr = accuracy_score(y_test, ypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c265c93-b344-4d33-a85d-a575d6bc11f1",
   "metadata": {},
   "source": [
    "##### 4 . 3 - Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a3877a-eebb-46cf-8f64-0b7eb987dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "steps = [('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "\n",
    "         ## linear SVC\n",
    "         ('svc', SVC(kernel = 'linear',\n",
    "                     class_weight='balanced',probability=True))\n",
    "\n",
    "         ## poly SVC\n",
    "         #('svc', SVC(kernel = 'poly', degree = 5,\n",
    "         #            class_weight='balanced', probability=True))\n",
    "\n",
    "         ## RBF SVC\n",
    "         #('svc', SVC(kernel = 'rbf', gamma = 'scale',\n",
    "         #            class_weight='balanced', probability=True))\n",
    "        ]\n",
    "svc_pipeline = Pipeline(steps)\n",
    "\n",
    "## Fitting\n",
    "svc_pipeline.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "## Evaluation\n",
    "## Training\n",
    "print('Support Vector Machine')\n",
    "print('---Training Results---')\n",
    "ypred_train = svc_pipeline.predict(X_train)\n",
    "mat_clf_train = confusion_matrix(y_train, ypred_train)\n",
    "report_clf_train = classification_report(y_train, ypred_train)\n",
    "print(mat_clf_train)\n",
    "print(report_clf_train)\n",
    "# ROC\n",
    "ypred_trainP = svc_pipeline.predict_proba(X_train)\n",
    "auc_train_svc = roc_auc_score(y_train, ypred_trainP[:,1])\n",
    "print(auc_train_svc)\n",
    "\n",
    "## Testing\n",
    "print('\\n---Testing Results---')\n",
    "ypred_test = svc_pipeline.predict(X_test)\n",
    "mat_clf_test = confusion_matrix(y_test, ypred_test)\n",
    "report_clf_test = classification_report(y_test, ypred_test)\n",
    "print(mat_clf_test)\n",
    "print(report_clf_test)\n",
    "# ROC\n",
    "ypred_testP = svc_pipeline.predict_proba(X_test)\n",
    "auc_test_svc = roc_auc_score(y_test, ypred_testP[:,1])\n",
    "print(auc_test_svc)\n",
    "\n",
    "\n",
    "## storing f1, precison, recall scores for comparison\n",
    "#f1\n",
    "f1_test_0_svc = f1_score(y_test, ypred_test, pos_label='0')\n",
    "f1_test_1_svc = f1_score(y_test, ypred_test, pos_label='1')\n",
    "#precision\n",
    "precision_test_0_svc = precision_score(y_test, ypred_test, pos_label='0')\n",
    "precision_test_1_svc = precision_score(y_test, ypred_test, pos_label='1')\n",
    "# recall\n",
    "recall_test_0_svc = recall_score(y_test, ypred_test, pos_label='0')\n",
    "recall_test_1_svc = recall_score(y_test, ypred_test, pos_label='1')\n",
    "# accuracy\n",
    "accuracy_test_svc = accuracy_score(y_test, ypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7708cf6-08ed-46cf-84c8-a2dd73f9cd21",
   "metadata": {},
   "source": [
    "##### 4 . 4 - Navis Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a6beb-6d65-4060-949f-800c9615259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pipeline\n",
    "steps = [('vect', CountVectorizer(ngram_range=(1,2))),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "\n",
    "        ## GaussianNB\n",
    "        #('gnb' , GaussianNB()),\n",
    "\n",
    "        ## MultinomialNB\n",
    "        ('mnb' , MultinomialNB(alpha=0.1)),\n",
    "\n",
    "        ## BernoulliNB\n",
    "        #('bnb' , BernoulliNB(alpha=1.0)),\n",
    "        ]\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "## Grid Search CV\n",
    "para = {\n",
    "    'mnb__alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    #'bnb__alpha': [0.01, 0.1, 1.0, 10.0],\n",
    "       }\n",
    "nb_pipeline = GridSearchCV(pipeline, para, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "## Fitting\n",
    "nb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "## Best Parameter\n",
    "print(\"\\nBest parameters:\", nb_pipeline.best_params_)\n",
    "\n",
    "## Evaluation\n",
    "## Training\n",
    "print('Navis Bayes')\n",
    "print('---Training Results---')\n",
    "ypred_train = nb_pipeline.predict(X_train)\n",
    "mat_clf_train = confusion_matrix(y_train, ypred_train)\n",
    "report_clf_train = classification_report(y_train, ypred_train)\n",
    "print(mat_clf_train)\n",
    "print(report_clf_train)\n",
    "# ROC\n",
    "ypred_trainP = nb_pipeline.predict_proba(X_train)\n",
    "auc_train_nb = roc_auc_score(y_train, ypred_trainP[:,1])\n",
    "print(auc_train_nb)\n",
    "\n",
    "## Testing\n",
    "print('\\n---Testing Results---')\n",
    "ypred_test = nb_pipeline.predict(X_test)\n",
    "mat_clf_test = confusion_matrix(y_test, ypred_test)\n",
    "report_clf_test = classification_report(y_test, ypred_test)\n",
    "print(mat_clf_test)\n",
    "print(report_clf_test)\n",
    "# ROC\n",
    "ypred_testP = nb_pipeline.predict_proba(X_test)\n",
    "auc_test_nb = roc_auc_score(y_test, ypred_testP[:,1])\n",
    "print(auc_test_nb)\n",
    "\n",
    "\n",
    "## Storing f1, precison, recall scores for comparison\n",
    "#f1\n",
    "f1_test_0_nb = f1_score(y_test, ypred_test, pos_label='0')\n",
    "f1_test_1_nb = f1_score(y_test, ypred_test, pos_label='1')\n",
    "#precision\n",
    "precision_test_0_nb = precision_score(y_test, ypred_test, pos_label='0')\n",
    "precision_test_1_nb = precision_score(y_test, ypred_test, pos_label='1')\n",
    "# recall\n",
    "recall_test_0_nb = recall_score(y_test, ypred_test, pos_label='0')\n",
    "recall_test_1_nb = recall_score(y_test, ypred_test, pos_label='1')\n",
    "# accuracy\n",
    "accuracy_test_nb = accuracy_score(y_test, ypred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8287f81-4957-4a55-8e77-447c8da2fbf9",
   "metadata": {},
   "source": [
    "### 5 - Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d347c-6ab4-423c-9309-1599b61fbadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ROC Scores\n",
    "# Training\n",
    "y=['KNN', 'Logistic Regression', 'Support Vector Machine', 'Naivs Bayes']\n",
    "x=[auc_train_knn, auc_train_lr, auc_train_svc, auc_train_nb]\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.barh(y, x, color='darkblue', height = 0.5)\n",
    "plt.title(\"ROC Score Comparison (Training Data)\")\n",
    "plt.show()\n",
    "\n",
    "# Testing\n",
    "y=['KNN', 'Logistic Regression', 'Support Vector Machine', 'Naivs Bayes']\n",
    "x=[auc_test_knn, auc_test_lr, auc_test_svc, auc_test_nb]\n",
    "\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.barh(y, x, color='darkblue', height = 0.5)\n",
    "plt.title(\"ROC Score Comparison (Testing Data)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35fdfbf-d7e1-4682-9888-b86e7581d559",
   "metadata": {},
   "outputs": [],
   "source": [
    "## f1 scores\n",
    "plotdata = pd.DataFrame({\n",
    "    \"Female\":[f1_test_0_knn,f1_test_0_lr,f1_test_0_svc,f1_test_0_nb],\n",
    "    \"Male\":[f1_test_1_knn,f1_test_1_lr,f1_test_1_svc,f1_test_1_nb]},\n",
    "    index=[\"KNN\", \"LR\", \"SVM\", \"NB\"])\n",
    "\n",
    "plotdata.plot(kind=\"bar\",figsize=(6, 3), color=['Orange','Blue'])\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"F1-Score Comparison(Testing)\")\n",
    "plt.xlabel(\"Testing\")\n",
    "plt.ylabel(\"F1-Score\")\n",
    "plt.show()\n",
    "print('\\n-----------\\n')\n",
    "\n",
    "## Precision\n",
    "plotdata = pd.DataFrame({\n",
    "    \"Female\":[precision_test_0_knn,precision_test_0_lr,precision_test_0_svc,precision_test_0_nb],\n",
    "    \"Male\":[precision_test_1_knn,precision_test_1_lr,precision_test_1_svc,precision_test_1_nb]},\n",
    "    index=[\"KNN\", \"LR\", \"SVM\", \"NB\"])\n",
    "\n",
    "plotdata.plot(kind=\"bar\",figsize=(6, 3), color=['Orange','Blue'])\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Precision Comparison(Testing)\")\n",
    "plt.xlabel(\"Testing\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.show()\n",
    "print('\\n-----------\\n')\n",
    "\n",
    "## Recall\n",
    "plotdata = pd.DataFrame({\n",
    "    \"Female\":[recall_test_0_knn,recall_test_0_lr,recall_test_0_svc,recall_test_0_nb],\n",
    "    \"Male\":[recall_test_1_knn,recall_test_1_lr,recall_test_1_svc,recall_test_1_nb]},\n",
    "    index=[\"KNN\", \"LR\", \"SVM\", \"NB\"])\n",
    "\n",
    "plotdata.plot(kind=\"bar\",figsize=(6, 3), color=['Orange','Blue'])\n",
    "plt.legend(loc='lower left')\n",
    "plt.title(\"Recall Comparison(Testing)\")\n",
    "plt.xlabel(\"Testing\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7996ad7-da32-4018-a456-2def3b6eb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Accuracy\n",
    "y = ['KNN', 'LR', 'SVM', 'NB']\n",
    "x = [accuracy_test_knn, accuracy_test_lr, accuracy_test_svc, accuracy_test_nb,]\n",
    "plt.figure(figsize=(5, 3))\n",
    "colors = ['skyblue', 'salmon', 'limegreen', 'orange']\n",
    "plt.bar(y, x, color=colors, width=0.5)\n",
    "plt.xlabel(\"Testing\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.title(\"Accuracy (Testing Data)\")\n",
    "for i, v in enumerate(x):\n",
    "    plt.text(i, v, f\"{v:.2f}\", ha='center', va='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864aacba-61a5-4033-8094-5e76fce8050f",
   "metadata": {},
   "source": [
    "### 6 - Check Your Name Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d2146e-41ff-4f38-9807-7679936ce9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enter a Name\n",
    "name = input('Enter a name : ')\n",
    "name = name.lower()\n",
    "\n",
    "## Predict\n",
    "prediction_knn = nb_pipeline.predict([name])\n",
    "prediction_lr = lr_pipeline.predict([name])\n",
    "prediction_svc = svc_pipeline.predict([name])\n",
    "prediction_nb = nb_pipeline.predict([name])\n",
    "\n",
    "gender_knn = pd.Series(prediction_knn).map({'1': 'Male', '0': 'Female'}).to_string().split()[1]\n",
    "gender_lr = pd.Series(prediction_lr).map({'1': 'Male', '0': 'Female'}).to_string().split()[1]\n",
    "gender_svc = pd.Series(prediction_svc).map({'1': 'Male', '0': 'Female'}).to_string().split()[1]\n",
    "gender_nb = pd.Series(prediction_nb).map({'1': 'Male', '0': 'Female'}).to_string().split()[1]\n",
    "\n",
    "print('KNN : ', gender_knn)\n",
    "print('LR  : ', gender_lr)\n",
    "print('SVC : ', gender_svc)\n",
    "print('NB  : ', gender_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147a3f4-d009-48cf-ba0d-1c9c68b7dd81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
